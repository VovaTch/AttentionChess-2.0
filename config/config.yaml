name: "AttentionChess2"
n_gpu: 1

arch: 
    type: "AttentionChess2"
    args:
      hidden_dim: 256
      num_encoders: 6
      num_experts: 4
      expert_dim: 2048
      dropout: 0.1
      aux_outputs: true

data_loader: 
    type: "BoardsLoader"
    args:
        dataset_path: 'data/boards_data/'
        batch_size: 128
        shuffle: true
        validation_split: 0.0
        num_workers: 0
        base_multiplier: 0.95
    
optimizer: 
    type: "AdamW"
    args:
        lr: 0.001
        weight_decay: 0.000001
        amsgrad: true
    
loss: 
    type: "Criterion"
    args:
        losses:
            -  "loss_policy"
            -  "loss_value"

loss_weights:
    policy: 1
    value: 2

metrics: 
    -  "loss_policy"
    -  "loss_value"

# lr_scheduler: 
#     type: "StepLR"
#     args: 
#         step_size: 50
#         gamma: 0.1

lr_scheduler:
    type: "OneCycleLR"
    args:
        max_lr: 0.01
        epochs: 100
        steps_per_epoch: 5000

trainer: 

    epochs: 100

    save_dir: "saved/"
    save_period: 20
    verbosity: 2
    
    monitor: "min val_loss"
    early_stop: 10

    tensorboard: true
